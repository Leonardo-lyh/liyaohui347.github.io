<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<meta name="robots" content="index, follow" />
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Yaohui Li, ÊùéËÄÄËæâ, Few-Shot Learning, Meta-Learning, Affective Computing, Nanjing University">
<link rel="stylesheet" href="./Files/jemdoc.css" type="text/css" />
<script src="jquery.min.js"></script>
<title>Yaohui Li ü§©(ÊùéËÄÄËæâ) </title>
    
    <head>
        <style>

            body{margin: 50px 130px;}

        </style>

    </head>
    
<body>
    <div id="layout-content">
        <table class="imgtable">
            <tbody>
                <tr>
                    <td>
                        <a href="./">
                            <img src="./Files/lyh.jpg" width="220px" height="242px">
                        </a>
                        &nbsp;
                    </td>
                    <td align="left">
                        <p>
                            <b>
                                <font size="+3" face="Times New Roman">Yaohui Li</font>
                                <font size="+3" face="ÂçéÊñá‰ªøÂÆã">(ÊùéËÄÄËæâ)</font>
                            </b>
                            <br>
                            <font size="+1" face="Times New Roman">Phd in Computer Science</font>, <a href="http://nlp.nju.edu.cn/homepage/">NJU NLP Group</a>
                            <br>
                            <a href="https://ai.nju.edu.cn/main.htm">School of Artifical Intelligence</a>
                            <br>
			    <a href="https://keysoftlab.nju.edu.cn/main.htm">National Key Laboratory for Novel Software Technology</a>
			    <br>
                            <a href="http://www.nju.edu.cn/">Nanjing University</a>
                            <br>
                            Address‚õ™: Nanjing University, Xianlin Campus, 163 Xianlin Avenue, Qixia District, Nanjing 210023, Jiangsu, China
                            <br>
                            Email: 
                            <a href="mailto:yaohuili@smail.nju.edu.cn">yaohuili@smail.nju.edu.cn</a>
                            ; 
                            <a href="mailto:liyaohui347@gmail.com">liyaohui347@gmail.com</a>
                            <br>

	                        [
	                        <a href="https://scholar.google.com/citations?user=pC2kmQoAAAAJ&hl=en">
	                            <span style="color:rgb(90, 21, 193)">Google Scholar</span>
	                        </a>
	                        ]
				[
	                        <a href="https://github.com/liyaohui347">
	                            <span style="color:rgb(90, 21, 193)">Github</span>
	                        </a>
	                        ]
		       </p>
                    </td>
                </tr>
            </tbody>
        </table>

<h2>About Me</h2>    
Currently, I am a Phd candidate supervised by <a href="https://cs.nju.edu.cn/zhangjb/index.htm">Assoc. Prof. Jianbing Zhang</a> and <a href="https://ai.nju.edu.cn/daixinyu/index.htm">Prof. Xinyu Dai</a> at <a href="https://ai.nju.edu.cn/main.htm">School of Artifical Intelligence</a> in <a href="http://www.nju.edu.cn/">Nanjing University</a>, which is led by <a href="https://cs.nju.edu.cn/zhouzh/index.htm">Prof. Zhihua Zhou</a>. 
Besides, I am also a member of <a href="http://nlp.nju.edu.cn/homepage/">NJUNLP</a> group, which is led by <a href="https://cs.nju.edu.cn/chenjiajun/index.htm">Prof. Jiajun Chen</a>. Before that, I received my M.S. and B.S. degree from Nanjing University in 2023 and 2020 respectively, supervised by <a href="https://scholar.google.com/citations?user=AC-EDw0AAAAJ&hl=en">Prof. Huaxiong Li</a>.
<br />
<h2>Experience</h2>
<ul>
<li>2021.06-2022.07  Research Intern in affective computing at OPPO Research Institute of Shanghai, supervised by <a href="https://yuzheyang.github.io/index.html">Yuzhe Yang</a> and <a href="https://dblp.org/pid/154/1961.html">Yaqian Li</a>.</li>
<li>2023.09-NOW Joint research student in AI for science at Institute for AI Industry Research, Tsinghua University, supervised by <a href="https://aclanthology.org/people/y/yawen-ouyang/">Yawen Ouyang</a> and <a href="https://zhouh.github.io/">Hao Zhou</a>.</li>
</ul>
<br />
<h2>Research Interest</h2>
I work in the field of computer vision, multi-modal learning and AI for science. Recently, I mainly focus on the following research topics:
<ul>
<li>Label-efficient learning: Learning with limited data effectively is an essential and promising topic in both industry and academia. I mainly work on learning generalizable representations from limited data for fast adaptation on target domains.</li>
<li>Vision-language models (VLM): Vision-language pre-training models have shown wide and promising future in research and applications. I mainly work on zero-/few-shot generalization and AIGC with the assistance of VLMs.</li>
<li>AI for materials: Extending AI algorithms to boost fundamental researches has become a promising and long-standing direction. I mainly work on generating optimal structures of chemical materials with required properties.</li>
</ul>
<br />
	    
<h2 id="-News">Recent News</h2>
<div style="height: 250px; overflow: auto;">
<ul>
<li><strong>[2023.09]: </strong>One paper on ‚ÄúText editing‚Äù is accepted to <a href="https://www.acmmm2023.org/">NeurIPS 2023</a> (CCF-A).</li>	
<li><strong>[2023.07]: </strong>One paper on ‚ÄúImage composition‚Äù is accepted to <a href="https://www.acmmm2023.org/">ACM Multimedia 2023</a> (CCF-A).</li>
<li><strong>[2023.01]: </strong>One paper on ‚ÄúFew-shot learning‚Äù is accepted to <a href="http://engine.scichina.com/doi/10.1007/s11432-022-3700-8">SCIS 2023</a> (CCF-A).</li>
<li><strong>[2022.07]: </strong>One paper on ‚ÄúAffective computing‚Äù is accepted to <a href="https://2022.acmmm.org/">ACM Multimedia 2022</a> (CCF-A).</li>
<li><strong>[2022.06]: </strong>One paper on ‚ÄúFew-shot learning‚Äù is accepted to <a href="https://www.icpr2022.com/">ICPR 2022</a>.</li>
<li><strong>[2022.06]: </strong>One paper on ‚ÄúFew-shot learning‚Äù is accepted to <a href="https://e-nns.org/icann2022/">ICANN 2022</a>.</li>
<li><strong>[2022.05]: </strong>One paper on ‚ÄúFew-shot learning‚Äù is accepted to <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=97">SPL 2022</a>.</li>
<li><strong>[2021.07]: </strong>One paper on ‚ÄúFew-shot learning‚Äù is accepted to <a href="http://2021.prcv.cn/">PRCV 2021</a>.</li>
</ul>
</div>
</td>
<br />
        <h2>Preprints</h2>
        <!--<h3>Conference Articles</h3>-->
        <ol>
<table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/qpn.jpg" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        <b>Yaohui Li</b>
                                        , Huaxiong Li, Haoxing Chen, Chunlin Chen.
                                        <br>
                                        <a href="https://arxiv.org/abs/2103.11384">Hierarchical Representation based Query-Specific Prototypical Network for Few-Shot Image Classification.</a>
                                        <br>
                                        <em>arXiv preprint arXiv: 2103.11384</em>
                                        , 2021.
                                        <br>
                                        [<a href="./Files/qpn.pdf" target="_blank">Paper</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>

        </ol>
<br />
        <h2>Publications</h2>
        <!--<h3>Conference Articles</h3>-->
       <ol>
	<table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/DiffUTE.jpg" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        Haoxing Chen, Zhuoer Xu, Zhangxuan Gu, Jun Lan, Xing Zheng, <b>Yaohui Li</b>, Changhua Meng, Huijia Zhu, Weiqiang Wang.
                                        <br>
                                        <a href="https://arxiv.org/abs/2305.10825">DiffUTE: Universal Text Editing Diffusion Model.</a>
                                        <br>
                                        In: <em>Thirty-senenth Conference on Neural Information Processing Systems (<b>NeurIPS</b>)</em>, 2023. (<b>CCF-A</b>)
					<br>
                                        [<a href="./Files/DiffUTE.pdf" target="_blank">Paper</a>]
                                        [<a href=" https://github.com/chenhaoxing/DiffUTE" target="_blank">Code</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>    
        <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/HDN.png" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        Haoxing Chen, Zhangxuan Gu, <b>Yaohui Li</b>, Jun Lan, Changhua Meng, Weiqiang Wang, Huaxiong Li.
                                        <br>
                                        <a href="https://arxiv.org/abs/2109.1293">Hierarchical Dynamic Image Harmonization.</a>
                                        <br>
                                         In: <em>ACM International Conference on Multimedia (<b>ACM MM</b>)</em>, 2023. (<b>CCF-A</b>) 
                                        <br>
                                         [<a href="https://arxiv.org/pdf/2211.08639.pdf" target="_blank">Paper</a>]
                                        [<a href=" https://github.com/chenhaoxing/HDNet" target="_blank">Code</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>

        <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/ss.png" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        Haoxing Chen
                                        , Huaxiong Li, <b>Yaohui Li</b>, Chunlin Chen.
                                        <br>
                                        <a href="https://arxiv.org/abs/2109.1293">Sparse Spatial Transformers for Few-Shot Learning.</a>
                                        <br>
                                        In: <em>Science China Information Science (<b>SCIS</b>)</em>
                                        , 2023, in press. (<b>CCF-A, IF=8.8</b>)
                                        <br>
                                        [<a href="./Files/chx-ssformers.pdf" target="_blank">Paper</a>]
                                        [<a href=" https://github.com/chenhaoxing/ssformers" target="_blank">Code</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>
        <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/mm_tapp.png" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        <b>Yaohui Li</b>, Yuzhe Yang, Huaxiong Li, Haoxing Chen, Liwu Xu, Leida Li, Yaqian Li, Yandong Guo.
                                        <br>
                                        <a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3548244"> Transductive Aesthetic Preference Propagation for Personalized Image Aesthetics Assessment.</a>
                                        <br>
                                         In: <em>ACM International Conference on Multimedia (<b>ACM MM</b>)</em>, 2022. (<b>CCF-A</b>) 
                                        <br>
                                        [<a href="https://dl.acm.org/doi/pdf/10.1145/3503161.3548244" target="_blank">Paper</a>]
					[<a href="https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3503161.3548244&file=mm22_fp2044.mp4" target="_blank">Video</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table> 
         


        <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/asl.png" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        Haoxing Chen
                                        , Huaxiong Li, <b>Yaohui Li</b>, Chunlin Chen.
                                        <br>
                                        <a href="https://ieeexplore.ieee.org/document/9790054">Shaping Visual Representations with Attributes for Few-Shot Recognition.</a>
                                        <br>
                                        <em>IEEE Signal Processing Letters</em>, vol. 29, pp. 1397-1401, 2022. (<b>CAA-B, SCI/SCIE, IF=3.201</b>)
                                        <br>
                                         [<a href="./Files/asl.pdf" target="_blank">Paper</a>]
                                        [<a href=" https://github.com/chenhaoxing/ASL" target="_blank">Code</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table> 
       <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/mml.png" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        Haoxing Chen
                                        , Huaxiong Li, <b>Yaohui Li</b>, Chunlin Chen.
                                        <br>
                                        <a href="https://arxiv.org/abs/2103.11383">Multi-level Metric Learning for Few-shot Image Recognition.</a>
                                        <br>
                                        In: <em>International Conference on Artificial Neural Networks (<b>ICANN</b>)</em>, 2022. (<b>CCF-C</b>)
                                        <br>
                                         [<a href="./Files/chx_mml.pdf" target="_blank">Paper</a>][<a href="https://github.com/chenhaoxing/M2L" target="_blank">Code</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>
       <table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/mata.jpg" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        Haoxing Chen
                                        , Huaxiong Li, <b>Yaohui Li</b>, Chunlin Chen.
                                        <br>
                                        <a href="https://arxiv.org/abs/2011.14479">Multi-scale Adaptive Task Attention Network for Few-Shot Learning.</a>
                                        <br>
                                        In: <em>International Conference on Pattern Recognition (<b>ICPR</b>)</em>, 2022. (<b>CCF-C</b>)
                                        <br>
                                         [<a href="./Files/chx-mata.pdf" target="_blank">Paper</a>]
                                         [<a href=" https://github.com/chenhaoxing/MATANet" target="_blank">Code</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>
<table class="imgtable">
                <tbody>
                    <tr>
                        <td>
                            <img src="./Files/mm.png" alt="WSFG" width="220px" height="110px">
                            &nbsp;
                        </td>
                        <td align="left">
                            <ul>
                                <li>
                                    <p>
                                        <b>Yaohui Li</b>
                                        , Huaxiong Li, Haoxing Chen, Chunlin Chen.
                                        <br>
                                        <a href="https://link.springer.com/chapter/10.1007%2F978-3-030-88004-0_36">Local Mutual Metric Network for Few-Shot Image Classification.</a>
                                        <br>
                                            In: <em>Chinese Conference on Pattern Recognition and Computer Vision (<b>PRCV</b>)</em>, 2021. (<b>CCF-C</b>)
                                        <br>
                                        
                                          [<a href="./Files/LMMN.pdf" target="_blank">Paper</a>]
                                    </p>
                                </li>
                            </ul>
                        </td>
                    </tr>
                </tbody>
            </table>
         
     <br />
	       
<A NAME="Awards"><h2>Awards and Honors</h2></A>
<font size="3"> 
<ul>
<li>Outstanding Graduates, Nanjing University, 2023
<li>National Scholarship, highest scholarship in China, Ministry of Education, China, 2022
<li>Outstanding Graduate Student, Nanjing University, 2021
<li>Industrial Bank Scholarship, Jiangsu Province, 2021
<li>1st Prize, Academic Scholarship, Nanjing University, 2020 & 2022
<li>National Grand Prize, Educational Robot Competition Of China (ERCC), 2018</li>

</ul>
</font>
<br />
	       
<h2>Academic Services</h2></A>
<font size="3"> 
<ul>
<li>Conference Reviewer of ACM MM 2023, AAAI 2023, ICPR 2022.
<li>Journal Reviewer of IEEE TIP, TNNLS</li>

</ul>
</font>
<br />

<div id="article"></div>
<div id="back_top">
<div class="arrow"></div>
<div class="stick"></div>
</div>
 
</body>    
</html>

